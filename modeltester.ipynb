{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ayush\n",
      "[nltk_data]     Yadav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import string\n",
    "model = keras.models.load_model('spam_classifier.h5')\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5 import QtWidgets\n",
    "from PyQt5.QtWidgets import QDialog, QApplication\n",
    "from PyQt5.QtCore import QCoreApplication\n",
    "from PyQt5.uic import loadUi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Input Shape: (None, 100)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model('spam_classifier.h5')\n",
    "\n",
    "\n",
    "input_shape = model.layers[0].input_shape\n",
    "print(\"Model Input Shape:\", input_shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuations_list = string.punctuation\n",
    "def remove_punctuations(text):\n",
    "\ttemp = str.maketrans('', '', punctuations_list)\n",
    "\treturn text.translate(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "\tstop_words = stopwords.words('english')\n",
    "\n",
    "\timp_words = []\n",
    "\n",
    "\t# Storing the important words\n",
    "\tfor word in str(text).split():\n",
    "\t\tword = word.lower()\n",
    "\n",
    "\t\tif word not in stop_words:\n",
    "\t\t\timp_words.append(word)\n",
    "\n",
    "\toutput = \" \".join(imp_words)\n",
    "\n",
    "\treturn output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(data):\n",
    "   tokenizer = Tokenizer()\n",
    "   tokenizer.fit_on_texts(data)\n",
    "\n",
    "   data_sequences = tokenizer.texts_to_sequences(data)\n",
    "   print(data_sequences)\n",
    "   maxlen = 100\n",
    "   data_sequences = pad_sequences(data_sequences, maxlen=maxlen,\n",
    "                                 padding='post', \n",
    "                              ) \n",
    "\n",
    "   predict = model.predict([data_sequences])\n",
    "   #print(len(data_sequences))\n",
    "\n",
    "   tokenlist = []\n",
    "   for i in predict:\n",
    "      if i>0.9:\n",
    "         tokenlist.append(i)\n",
    "   print(len(data_sequences))\n",
    "   print(len(tokenlist))\n",
    "\n",
    "   if len(tokenlist)>len(data_sequences)*0.45:\n",
    "      return \"Spam\"\n",
    "   else:\n",
    "      return \"Not Spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9], [1], [4], [8], [1], [4], [], [16], [6], [10], [6], [5], [], [], [11], [6], [], [14], [3], [12], [7], [2], [2], [4], [], [], [11], [1], [20], [], [14], [3], [4], [13], [], [8], [3], [13], [10], [], [3], [7], [2], [], [13], [1], [12], [], [17], [1], [14], [6], [4], [18], [], [1], [16], [2], [7], [], [15], [1], [7], [], [], [], [6], [4], [], [3], [8], [8], [6], [5], [6], [1], [4], [], [5], [1], [], [5], [11], [2], [], [17], [1], [12], [19], [9], [2], [], [1], [15], [], [8], [3], [13], [10], [], [], [13], [1], [12], [], [23], [], [9], [9], [], [21], [2], [], [10], [19], [2], [4], [8], [6], [4], [18], [], [3], [5], [], [21], [7], [1], [1], [22], [], [11], [12], [4], [5], [], [], [], [6], [], [17], [3], [4], [], [10], [2], [2], [], [1], [4], [2], [], [15], [12], [7], [5], [11], [2], [7], [], [8], [3], [13], [], [20], [6], [5], [11], [], [1], [12], [7], [], [14], [2], [5], [3], [9], [10], [], [], [19], [2], [1], [19], [9], [2], [], [], [], [3], [4], [8], [], [1], [4], [2], [], [2], [24], [5], [7], [3], [], [8], [3], [13], [], [20], [6], [5], [11], [], [7], [1], [8], [7], [6], [18], [1], [], [], [], [15], [7], [1], [14], [], [7], [3], [17], [], [], [], [9], [1], [1], [22], [6], [4], [18], [], [3], [5], [], [1], [12], [7], [], [6], [4], [15], [9], [3], [5], [6], [1], [4], [], [], [14], [1], [8], [2], [9], [], [], [], [8], [1], [], [13], [1], [12], [], [11], [3], [16], [2], [], [25], [], [], [], [8], [3], [13], [10], [], [], [], [], [3], [9], [9], [], [5], [11], [2], [], [21], [2], [10], [5], [], [], [10], [5], [2], [16], [2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 6ms/step\n",
      "311\n",
      "172\n",
      "Spam\n"
     ]
    }
   ],
   "source": [
    "print(predictor(\"london visit  hi maureen  how many days are you coming over for ? in addition to the couple of days  you ' ll be spending at brook hunt , i can see one further day with our metals  people , and one extra day with rodrigo ( from rac ) looking at our inflation  model . do you have 4 + days ?  all the best  steve\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Spam(QDialog):\n",
    "    def __init__(self):\n",
    "        super(Spam, self).__init__()\n",
    "        loadUi('spam.ui', self)\n",
    "        self.check.clicked.connect(self.detector)\n",
    "        \n",
    "    def detector(self):\n",
    "        email = self.email.toPlainText()\n",
    "        data = email\n",
    "        data = remove_punctuations(data)\n",
    "        data = remove_stopwords(data)\n",
    "        result = predictor(data)\n",
    "        self.result.setText(result)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app = QCoreApplication.instance()\n",
    "if app is None:\n",
    "    app = QApplication(sys.argv)\n",
    "mainwindow = Spam()\n",
    "widget = QtWidgets.QStackedWidget()\n",
    "widget.addWidget(mainwindow)\n",
    "widget.setFixedHeight(606)\n",
    "widget.setFixedWidth(682)\n",
    "widget.show()\n",
    "app.exec_()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
